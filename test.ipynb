{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"V18IgBJIZHL3"},"outputs":[],"source":["import os\n","import cv2\n","import math\n","import torch\n","import shutil \n","import random\n","import numpy as np \n","import pandas as pd \n","from tqdm import tqdm\n","from PIL import Image\n","import torch.nn as nn\n","from torch import cuda\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader, Dataset\n","from skimage.color import rgb2lab, lab2rgb\n","import torchvision.models as models"]},{"cell_type":"code","source":["!pip install fastai==2.4\n","!pip install pillow scikit-video"],"metadata":{"id":"3lAbHhXOMf7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ACDj7f2kZNsm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651308021819,"user_tz":-330,"elapsed":6,"user":{"displayName":"Harsh Vardhan Bhadauriya","userId":"01145987489048234126"}},"outputId":"e794f9ee-e026-41f8-885b-b7cc149875b3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":2}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","source":["import skvideo.io\n","import numpy as np\n","from PIL import Image\n","def make_video(read_path, video_save_path, count, fps):\n","  writer = skvideo.io.FFmpegWriter(video_save_path, \n","                        inputdict={'-r': str(fps)},\n","                        outputdict={'-r': str(fps), '-c:v': 'libx264', '-preset': 'ultrafast', '-pix_fmt': 'yuv444p'})\n","  for i in range(0, count):\n","    image_name = read_path + \"%d.png\" % i\n","    image = Image.open(image_name)\n","    image = np.array(image, dtype=np.uint8)\n","    writer.writeFrame(image)\n","  writer.close()"],"metadata":{"id":"EO9iRyqoG4Kz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","import shutil\n","def save_model(model):\n","  drive.mount('/content/drive')\n","  shutil.copy(\"/content/\" + model, \"/content/drive/MyDrive/cv thesis/model/trained_models_colorization_net\")\n","  print(\"Model Saved\")\n","  drive.flush_and_unmount()\n","\n","def load_model(model):\n","  drive.mount('/content/drive')\n","  shutil.copy(\"/content/drive/MyDrive/cv thesis/model/trained_models_colorization_net/\" + model, '/content/')\n","  print(\"Model Loaded\")\n","  drive.flush_and_unmount()\n","\n","def save_video(vid):\n","  drive.mount('/content/drive')\n","  shutil.copy(\"/content/\" + vid, \"/content/drive/MyDrive/cv thesis/\")\n","  print(\"Video Saved\")\n","  drive.flush_and_unmount()"],"metadata":{"id":"4Nw9rCMTDFf5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h3>Colorization Network"],"metadata":{"id":"ogahjrctCS6X"}},{"cell_type":"code","source":["!pip install --upgrade --no-cache-dir gdown\n","!gdown --id 1bxoWFitjFk_eX9laOZhMQE_tjpLMOrDO #charlie"],"metadata":{"id":"rGoaxp1lCdeL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip Charlie.zip"],"metadata":{"id":"1bW5Riw0ETWz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown --id 1V68xX9CyfPPhgqAzwZTmnfaJhXK7DMdd #network.py\n","!gdown --id 1Mgvfb9BfIjmRH3G9ju0NHWhKOpvbF5mS #loss.py\n","!gdown --id 1Ta1BoQRk9GP0BoME86wro8kk3o6f86rb #dataset.py"],"metadata":{"id":"M3Lgmw_HDZ1v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from dataset import *\n","from network import *\n","from loss import *"],"metadata":{"id":"sJTDD7tjCdgT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["load_model(\"netG_90.pt\")\n","load_model(\"netG_150.pt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Cyvh2JXCdin","executionInfo":{"status":"ok","timestamp":1651308129936,"user_tz":-330,"elapsed":30787,"user":{"displayName":"Harsh Vardhan Bhadauriya","userId":"01145987489048234126"}},"outputId":"2b71b07c-36ec-408a-c003-1632ef6264d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Model Loaded\n","Mounted at /content/drive\n","Model Loaded\n"]}]},{"cell_type":"code","source":["size_transform = transforms.Compose([\n","        ])\n","transform = transforms.Compose([\n","            transforms.ToTensor()\n","        ])\n","\n","frames = ImageDataset(r\"/content/Charlie-1\", r\"/content/annotation.csv\", size_transform, transform)\n","frames_loader = DataLoader(dataset = frames, batch_size = 1, num_workers = 0, shuffle = False, pin_memory = True, drop_last = False)\n","print(len(frames_loader), len(frames_loader.dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdbDTd5oCdkx","executionInfo":{"status":"ok","timestamp":1651308136422,"user_tz":-330,"elapsed":429,"user":{"displayName":"Harsh Vardhan Bhadauriya","userId":"01145987489048234126"}},"outputId":"9b956881-bdd3-4f7d-9152-9ada234060fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2064 2064\n"]}]},{"cell_type":"markdown","source":["<h3>After 90 epochs"],"metadata":{"id":"Pf57WKIEUojH"}},{"cell_type":"code","source":["generator_model = 'netG_90.pt'\n","net_G = ColorNet('None')  \n","net_G.to(device)    \n","print('Loaded model onto GPU.') \n","if os.path.exists(\"/content/\" + generator_model):\n","  checkpoint = torch.load(\"/content/\" + generator_model)\n","  net_G.load_state_dict(checkpoint)\n","  print(\"Pretrained Model loaded\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s3Hw-tHVCdo-","executionInfo":{"status":"ok","timestamp":1651308148430,"user_tz":-330,"elapsed":4979,"user":{"displayName":"Harsh Vardhan Bhadauriya","userId":"01145987489048234126"}},"outputId":"e9667f3d-7fba-473b-cb0e-953a189b9edb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded colorization net.\n","Loaded model onto GPU.\n","Pretrained Model loaded\n"]}]},{"cell_type":"code","source":["!rm -rf /content/colored_frames_epoch_90/*\n","!ls /content/colored_frames_epoch_90/* | wc -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2InVvUneTFGc","executionInfo":{"status":"ok","timestamp":1651235811878,"user_tz":-330,"elapsed":717,"user":{"displayName":"Harsh Vardhan Bhadauriya","userId":"01145987489048234126"}},"outputId":"457fa9f6-7d10-47c4-a403-e6cd2f2c146a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access '/content/colored_frames_epoch_90/*': No such file or directory\n","0\n"]}]},{"cell_type":"code","source":["!mkdir colored_frames_epoch_90"],"metadata":{"id":"gXz0bKv_THK8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","net_G.eval()\n","save_path = '/content/colored_frames_epoch_90/'  "],"metadata":{"id":"EOAdOOSiTJGu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for (gray, ab) in tqdm(frames_loader):\n","    L = gray.to(device = device, dtype = torch.float32)\n","    ab = ab.to(device = device, dtype = torch.float32)\n","    output = net_G(L) \n","        \n","    fake = torch.cat([L, output], dim = 1).detach().cpu().numpy()\n","    for i in range(fake.shape[0]):\n","      color_image = fake[i]\n","      color_image = color_image.transpose((1, 2, 0))\n","      color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n","      color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n","      color_image = lab2rgb(color_image.astype(np.float64))  * 255.0\n","      # # print(color_image.shape)\n","      im = Image.fromarray(color_image.astype(np.uint8))\n","      im.save(save_path +\"%d.png\" % count)\n","      # color_image = cv2.cvtColor(color_image.astype(np.uint8),cv2.COLOR_LAB2BGR)\n","      # cv2.imwrite(save_path +\"frame%d.jpeg\" % count, color_image)\n","      count+=1\n","      plt.axis(False)\n","      plt.imshow(im)\n","      plt.show()"],"metadata":{"id":"Jn-hV1guCdrS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["read_path = '/content/colored_frames_epoch_90/'\n","video_save_path = \"/content/colorization_net_charlie_epoch_90.mp4\"\n","fps = 25\n","make_video(read_path, video_save_path, count, fps)"],"metadata":{"id":"xnaIa6uPCduM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_video(\"colorization_net_charlie_epoch_90.mp4\")"],"metadata":{"id":"ISdtVvptF4pN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651238256419,"user_tz":-330,"elapsed":20677,"user":{"displayName":"Harsh Vardhan Bhadauriya","userId":"01145987489048234126"}},"outputId":"049cc713-4642-4365-ca50-eb37cbe20629"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Video Saved\n"]}]},{"cell_type":"code","source":["for (gray, ab) in tqdm(frames_loader):\n","    L = gray.to(device = device, dtype = torch.float32)\n","    ab = ab.to(device = device, dtype = torch.float32)\n","    output = net_G(L) \n","        \n","    fake = torch.cat([L, output], dim = 1).detach().cpu().numpy()\n","    for i in range(fake.shape[0]):\n","      color_image = fake[i]\n","      color_image = color_image.transpose((1, 2, 0))\n","      color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n","      color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n","      color_image = lab2rgb(color_image.astype(np.float64))  * 255.0\n","      # # print(color_image.shape)\n","      im = Image.fromarray(color_image.astype(np.uint8))\n","      # im.save(save_path +\"%d.png\" % count)\n","      # color_image = cv2.cvtColor(color_image.astype(np.uint8),cv2.COLOR_LAB2BGR)\n","      # cv2.imwrite(save_path +\"frame%d.jpeg\" % count, color_image)\n","      # count+=1\n","      plt.axis(False)\n","      plt.imshow(im)\n","      plt.show()"],"metadata":{"id":"8S7Qx4ppouDp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h3>After 150 epochs"],"metadata":{"id":"UY6rKc_6_dh6"}},{"cell_type":"code","source":["generator_model = 'netG_150.pt'\n","net_G = ColorNet('None')  \n","net_G.to(device)    \n","print('Loaded model onto GPU.') \n","if os.path.exists(\"/content/\" + generator_model):\n","  checkpoint = torch.load(\"/content/\" + generator_model)\n","  net_G.load_state_dict(checkpoint)\n","  print(\"Pretrained Model loaded\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_lLQmnZ_gxl","executionInfo":{"status":"ok","timestamp":1651257633328,"user_tz":-330,"elapsed":602,"user":{"displayName":"Harsh Vardhan Bhadauriya","userId":"01145987489048234126"}},"outputId":"2f66583b-b89c-4754-b29b-9d8512213aab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded colorization net.\n","Loaded model onto GPU.\n","Pretrained Model loaded\n"]}]},{"cell_type":"code","source":["net_G.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzgYnatS_i4W","executionInfo":{"status":"ok","timestamp":1651257637041,"user_tz":-330,"elapsed":568,"user":{"displayName":"Harsh Vardhan Bhadauriya","userId":"01145987489048234126"}},"outputId":"e8d13f6d-aed5-4025-a6cb-2affb67659b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ColorNet(\n","  (midlevel_resnet): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (global_resnet): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (fusion_and_colorization_net): ColorizationNet(\n","    (fusion): Linear(in_features=640, out_features=128, bias=True)\n","    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (deconv1_new): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv5): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (upsample): Upsample(scale_factor=2.0, mode=nearest)\n","  )\n",")"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["for (gray, ab) in tqdm(frames_loader):\n","    L = gray.to(device = device, dtype = torch.float32)\n","    ab = ab.to(device = device, dtype = torch.float32)\n","    output = net_G(L) # throw away class predictions\n","        \n","    fake = torch.cat([L, output], dim = 1).detach().cpu().numpy()\n","    for i in range(fake.shape[0]):\n","      color_image = fake[i]\n","      color_image = color_image.transpose((1, 2, 0))\n","      color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n","      color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n","      color_image = lab2rgb(color_image.astype(np.float64))  * 255.0\n","      # # print(color_image.shape)\n","      im = Image.fromarray(color_image.astype(np.uint8))\n","      # im.save(save_path +\"%d.png\" % count)\n","      # color_image = cv2.cvtColor(color_image.astype(np.uint8),cv2.COLOR_LAB2BGR)\n","      # cv2.imwrite(save_path +\"frame%d.jpeg\" % count, color_image)\n","      # count+=1\n","      plt.axis(False)\n","      plt.imshow(im)\n","      plt.show()"],"metadata":{"id":"LKhx4lEF_mGT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h1>Colorization with UNet"],"metadata":{"id":"2B2HYmMJF5nw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NLaxjL45ZRwa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651262144433,"user_tz":-330,"elapsed":2720,"user":{"displayName":"Shreyansh Jain","userId":"06649601165379567892"}},"outputId":"cf5b3be8-8842-44b3-8d42-3ff5ed0dd14c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1l_KBj-pF67Zhhh7s1hNsEKP29Piz9dPD\n","To: /content/color_network.py\n","100% 1.66k/1.66k [00:00<00:00, 2.90MB/s]\n"]}],"source":["# !pip install --upgrade --no-cache-dir gdown\n","!gdown --id 1l_KBj-pF67Zhhh7s1hNsEKP29Piz9dPD  #color_netwrok\n","# !gdown --id 1bxoWFitjFk_eX9laOZhMQE_tjpLMOrDO #charlie\n","# !unzip Charlie.zip"]},{"cell_type":"code","source":["# !gdown --id 1r_2E4DNVnO5puqT3YmzM64rFOCtB69ZT  #final\n","# !gdown --id 1i_J_XOI8tGcavvB9xcsKK0_Z85oVg-VM #resnet\n","!gdown --id 1KL1lpiYLWkn5WGKNunJeL4bpBuTQN2JP #net_G final\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IDGYQhWnL-fA","executionInfo":{"status":"ok","timestamp":1651262153341,"user_tz":-330,"elapsed":7490,"user":{"displayName":"Shreyansh Jain","userId":"06649601165379567892"}},"outputId":"2b4801a4-3502-47a7-f01e-90df399de958"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1KL1lpiYLWkn5WGKNunJeL4bpBuTQN2JP\n","To: /content/net_G_unet_final.pt\n","100% 125M/125M [00:01<00:00, 105MB/s]\n"]}]},{"cell_type":"code","source":["from color_network import *"],"metadata":{"id":"Rdv0kqRcKuS4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np \n","import pandas as pd \n","from PIL import Image\n","from torch.utils.data import Dataset\n","from skimage.color import rgb2lab, rgb2gray\n","\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, root, captions_file, color_transform = None, transform = None):\n","        self.df = pd.read_csv(captions_file, index_col=None)\n","        self.transform = transform\n","        self.color_transform = color_transform\n","        self.images = self.df[\"image\"]        \n","        self.root = root\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        img = Image.open(os.path.join(self.root, self.images[index])).convert(\"RGB\")\n","        if self.color_transform:\n","          img = self.color_transform(img)\n","        img = np.array(img)\n","      \n","        img_lab = rgb2lab(img).astype(\"float32\") \n","        img_lab = transforms.ToTensor()(img_lab)\n","        L = img_lab[[0], ...] / 50. - 1. # Between -1 and 1\n","        ab = img_lab[[1, 2], ...] / 110. # Between -1 and 1\n","        \n","        if self.transform:\n","            L = self.transform(L)\n","            ab = self.transform(ab)\n","\n","        return L , ab\n"," "],"metadata":{"id":"U5ZAboisN2R8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net_G = Generator(n_input=1, n_output=2, size=256)\n","net_G.load_state_dict(torch.load(\"net_G_unet_final.pt\", map_location=device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MnzzgfBh9qvM","executionInfo":{"status":"ok","timestamp":1651262186748,"user_tz":-330,"elapsed":6564,"user":{"displayName":"Shreyansh Jain","userId":"06649601165379567892"}},"outputId":"fe59fb96-d233-41a5-cba6-1fbddb42121a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["frames = ImageDataset(r\"/content/Charlie-1\", r\"/content/annotation.csv\")\n","frames_loader = DataLoader(dataset = frames, batch_size = 1, num_workers = 0, shuffle = False, pin_memory = True, drop_last = False)\n","print(len(frames_loader), len(frames_loader.dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wz0ke-NqNdAz","executionInfo":{"status":"ok","timestamp":1651262189968,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shreyansh Jain","userId":"06649601165379567892"}},"outputId":"03daf463-f293-49ed-b3a1-284f3a09a2d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2064 2064\n"]}]},{"cell_type":"code","source":["!rm -rf /content/colored_frames_unet/*\n","!ls /content/colored_frames_unet/* | wc -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tCU9g82FUafa","executionInfo":{"status":"ok","timestamp":1651246970312,"user_tz":-330,"elapsed":517,"user":{"displayName":"Harsh Vardhan Bhadauriya","userId":"01145987489048234126"}},"outputId":"cef3130c-8a7b-47f1-eeb5-5db771896444"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access '/content/colored_frames_unet/*': No such file or directory\n","0\n"]}]},{"cell_type":"code","source":["!mkdir colored_frames_unet"],"metadata":{"id":"j3TDpXKROGE0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net_G.eval()\n","count = 0\n","# save_path = '/content/colored_frames_unet/'  "],"metadata":{"id":"LfXsUroaOOKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for (gray, ab) in tqdm(frames_loader):\n","    L = gray.to(device = device, dtype = torch.float32)\n","    ab = ab.to(device = device, dtype = torch.float32)\n","    out_ab = net_G(L) #output\n","        \n","    fake = torch.cat([L, out_ab], dim = 1).detach().cpu().numpy()\n","\n","    for i in range(fake.shape[0]):\n","      color_image = fake[i]\n","      color_image = color_image.transpose((1, 2, 0))\n","      color_image[:, :, 0:1] = (color_image[:, :, 0:1] + 1) * 50\n","      color_image[:, :, 1:3] = color_image[:, :, 1:3] * 110\n","      color_image = lab2rgb(color_image.astype(np.float64))  * 255.0\n","      im = Image.fromarray(color_image.astype(np.uint8))\n","      # im.save(save_path +\"%d.png\" % count)\n","      count+=1\n","      plt.axis(False)\n","      plt.imshow(im)\n","      plt.show()"],"metadata":{"id":"FwZEXtdWOBgK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["read_path = '/content/colored_frames_unet/'\n","video_save_path = \"/content/unet_charlie_colored.mp4\"\n","fps = 25\n","make_video(read_path, video_save_path, count, fps)"],"metadata":{"id":"NkzH9sLdZxas"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_video(\"unet_charlie_colored.mp4\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqwz4uURazkK","executionInfo":{"status":"ok","timestamp":1651234882448,"user_tz":-330,"elapsed":20476,"user":{"displayName":"Harsh Vardhan Bhadauriya","userId":"01145987489048234126"}},"outputId":"b0bdd253-0422-403d-9c1a-8b4c379a6d91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Video Saved\n"]}]},{"cell_type":"code","source":["for (gray, ab) in tqdm(frames_loader):\n","    L = gray\n","\n","        \n","    for i in range(L.shape[0]):\n","      gray_image = L[i][0]\n","      # gray_image = gray_image.transpose((1, 2, 0))\n","      print(gray_image.shape)\n","      # color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n","      # color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n","      # color_image = lab2rgb(color_image.astype(np.float64))  * 255.0\n","      # # print(color_image.shape)\n","      # im = Image.fromarray(color_image.astype(np.uint8))\n","      # im.save(save_path +\"%d.png\" % count)\n","      # color_image = cv2.cvtColor(color_image.astype(np.uint8),cv2.COLOR_LAB2BGR)\n","      # cv2.imwrite(save_path +\"frame%d.jpeg\" % count, color_image)\n","      \n","      plt.axis(False)\n","      plt.imshow(gray_image, \"gray\")\n","      plt.show()"],"metadata":{"id":"rwHnpyaa_W3y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h1> Colorization network with Wasserstein loss"],"metadata":{"id":"TBQrU_ltvBqY"}},{"cell_type":"code","source":["!pip install --upgrade --no-cache-dir gdown\n","!gdown --id 1oRV2Y0DZYDNBfTMkcEB6V_GL82u-YzFX #dataset\n","!gdown --id 1ACRzAIg_v64iZ6fwOO7CQmt4D0vxLczV #utils\n","!gdown --id 1TeY1q_vvZia4ryIKLtq9aIkG9vGjSEb- #patch_discriminator\n","!gdown --id 1FsLpLN612SZATZQhnq2h90V5HcKmF5SI #generator\n","\n","from utils import *\n","from dataset import *\n","from discriminator import *\n","from encoder import *"],"metadata":{"id":"0M06psuQAqDy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651261858358,"user_tz":-330,"elapsed":9010,"user":{"displayName":"Shreyansh Jain","userId":"06649601165379567892"}},"outputId":"71347753-bea1-4887-e615-e331d039e6a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1oRV2Y0DZYDNBfTMkcEB6V_GL82u-YzFX\n","To: /content/dataset.py\n","100% 818/818 [00:00<00:00, 1.66MB/s]\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1ACRzAIg_v64iZ6fwOO7CQmt4D0vxLczV\n","To: /content/utils.py\n","100% 712/712 [00:00<00:00, 1.14MB/s]\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1TeY1q_vvZia4ryIKLtq9aIkG9vGjSEb-\n","To: /content/discriminator.py\n","100% 1.44k/1.44k [00:00<00:00, 2.50MB/s]\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1FsLpLN612SZATZQhnq2h90V5HcKmF5SI\n","To: /content/encoder.py\n","100% 563/563 [00:00<00:00, 1.06MB/s]\n"]}]},{"cell_type":"code","source":["frames = ImageDataset(r\"/content/Charlie-1\", r\"/content/annotation.csv\")\n","frames_loader = DataLoader(dataset = frames, batch_size = 1, num_workers = 0, shuffle = False, pin_memory = True, drop_last = False)\n","print(len(frames_loader), len(frames_loader.dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dY0OLYr_vTr5","executionInfo":{"status":"ok","timestamp":1651262247790,"user_tz":-330,"elapsed":363,"user":{"displayName":"Shreyansh Jain","userId":"06649601165379567892"}},"outputId":"bda1f966-d593-45d7-9ab9-9fdf1288c85a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2064 2064\n"]}]},{"cell_type":"code","source":["load_model(\"net_G-final.pth\")\n","net_G = Generator(n_input=1, n_output=2, size=256)\n","net_G.load_state_dict(torch.load(\"./net_G-final.pth\", map_location=device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rl3p_QdvvdE","executionInfo":{"status":"ok","timestamp":1651262293519,"user_tz":-330,"elapsed":8495,"user":{"displayName":"Shreyansh Jain","userId":"06649601165379567892"}},"outputId":"c3821bc7-cfb7-46f1-845f-aa797a0de230"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Model Loaded\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["net_G.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GvPE_AHMvxOU","executionInfo":{"status":"ok","timestamp":1651262293908,"user_tz":-330,"elapsed":4,"user":{"displayName":"Shreyansh Jain","userId":"06649601165379567892"}},"outputId":"b3d3ffd3-0c47-4650-8425-fc2f552d7d0f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DynamicUnet(\n","  (layers): ModuleList(\n","    (0): Sequential(\n","      (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (4): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Sequential(\n","      (0): ConvLayer(\n","        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (1): ConvLayer(\n","        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","    )\n","    (4): UnetBlock(\n","      (shuf): PixelShuffle_ICNR(\n","        (0): ConvLayer(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (1): ReLU()\n","        )\n","        (1): PixelShuffle(upscale_factor=2)\n","      )\n","      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): ConvLayer(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (conv2): ConvLayer(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (relu): ReLU()\n","    )\n","    (5): UnetBlock(\n","      (shuf): PixelShuffle_ICNR(\n","        (0): ConvLayer(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (1): ReLU()\n","        )\n","        (1): PixelShuffle(upscale_factor=2)\n","      )\n","      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): ConvLayer(\n","        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (conv2): ConvLayer(\n","        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (relu): ReLU()\n","    )\n","    (6): UnetBlock(\n","      (shuf): PixelShuffle_ICNR(\n","        (0): ConvLayer(\n","          (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n","          (1): ReLU()\n","        )\n","        (1): PixelShuffle(upscale_factor=2)\n","      )\n","      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): ConvLayer(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (conv2): ConvLayer(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (relu): ReLU()\n","    )\n","    (7): UnetBlock(\n","      (shuf): PixelShuffle_ICNR(\n","        (0): ConvLayer(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (1): ReLU()\n","        )\n","        (1): PixelShuffle(upscale_factor=2)\n","      )\n","      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): ConvLayer(\n","        (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (conv2): ConvLayer(\n","        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (relu): ReLU()\n","    )\n","    (8): PixelShuffle_ICNR(\n","      (0): ConvLayer(\n","        (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n","        (1): ReLU()\n","      )\n","      (1): PixelShuffle(upscale_factor=2)\n","    )\n","    (9): ResizeToOrig()\n","    (10): MergeLayer()\n","    (11): ResBlock(\n","      (convpath): Sequential(\n","        (0): ConvLayer(\n","          (0): Conv2d(97, 97, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU()\n","        )\n","        (1): ConvLayer(\n","          (0): Conv2d(97, 97, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","      (idpath): Sequential()\n","      (act): ReLU(inplace=True)\n","    )\n","    (12): ConvLayer(\n","      (0): Conv2d(97, 2, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (13): ToTensorBase(tensor_cls=<class 'fastai.torch_core.TensorBase'>)\n","  )\n",")"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["for (gray, ab) in tqdm(frames_loader):\n","    L = gray.to(device = device, dtype = torch.float32)\n","    ab = ab.to(device = device, dtype = torch.float32)\n","    out_ab = net_G(L) #output   \n","    fake = torch.cat([L, out_ab], dim = 1).detach().cpu().numpy()\n","    for i in range(fake.shape[0]):\n","      color_image = fake[i]\n","      color_image = color_image.transpose((1, 2, 0))\n","      color_image[:, :, 0:1] = (color_image[:, :, 0:1] + 1) * 50\n","      color_image[:, :, 1:3] = color_image[:, :, 1:3] * 110\n","      color_image = lab2rgb(color_image.astype(np.float64))  * 255.0\n","      im = Image.fromarray(color_image.astype(np.uint8))\n","      plt.axis(False)\n","      plt.imshow(im)\n","      plt.show()"],"metadata":{"id":"BfVGIfAE02aK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"XLpyXSN84one"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Copy of test.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}